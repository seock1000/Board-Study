## CQRS 요약

- 현재 게시판 서비스의 문제점
  - 증설 시 문제
    - 게시판 도메인의 특징상 읽기 트래픽 >>>>> 쓰기 트래픽
    - 읽기 트래픽 폭증으로 서버 증설이 필요한 경우 관련이 없는 쓰기를 포함하여 증설이 필요하게 됨
  - Micro Service 간 순환참조 문제
    - Article 도메인은 View, Like, Comment 등 서비스와 종속성을 가짐 -> 순환참조 발생
      - 데이터 무결성을 위해 View, Like, Comment 생성 등에서 Article의 유효성 검증/데이터 요청 필요
    - Micro Service 간 순환 참조로 독립적 배포, 유지보수 어려움, 장애전파 가능성 증가, 테스트 어려움 증가 등
- 해결방안 : 게시글 조회 도메인 분리
  - ArticleRead 도메인 생성
    - ArticleRead 도메인 : 게시글 조회 전용 도메인, 각 Micro Service로 데이터를 요청하여 조회모델 생성
    - Article 도메인 : 게시글 작성, 수정, 삭제 등 쓰기 전용 도메인
    - Like, Comment, View 등 도메인은 ArticleRead 도메인과만 연관관계 가짐
  - 읽기 트래픽에 대해 독립적 증설 가능
  - Micro Service 간 순환참조 문제 해결
    - Article 도메인은 Like, Comment, View 등과의 연관관계 제거
    - 각 Micro Service는 ArticleRead 도메인과만 연관관계 가짐
  - 단점
    - 데이터 요청 시 네트워크 비용 증가
    - 조회에 대해 각 서비스에 부하 전파
    - 데이터 조합 & 질의 비용 증가

- CQRS
  - Command Query Responsibility Segregation
  - 데이터 변경(Command)과 조회(Query)의 책임 분리
  - 책임분리의 범위
    - [좁은 범위] 클래스레벨 -> 패키지레벨 -> 서비스레벨 -> 데이터저장소레벨 [넓은 범위]
  - 게시판 서비스 CQRS 적용
    - Command 서버 : 게시글, 댓글, 좋아요
    - Query 서버 : 게시글 조회
    - 게시글 조회 서비스에서 자체 DB 구축 및 관리 - 데이터저장소레벨 분리
    - 게시글 조회 서비스로 변경되는 데이터 동기화 필요
      - polling, 이벤트 기반 등 활용 가능
      - 현재 Kafka를 메시지 브로커로 구축하였으므로 이를 활용
      - 이벤트는 이미 전송중이므로 Consumer Group 추가로 해결 가능
    - 게시글 조회 서비스에서는 command 서비스와 별도로 조회모델 구축 및 관리
      - join 비용 감소 및 복잡한 질의 처리 용이
      - Query Model 단건 조회로 모든 필요 데이터 조회 가능
  - 게시글 조회 전략
    - Redis
      - 빠르지만 메모리 기반으로 높은 저장 비용
      - 최신글이 조회되는 경우가 많은 게시판 특성을 고려하여, TTL 24시간 설정하여 최신글만 Redis 저장
    - Redis miss 시 전략
      - Command 서비스로부터 직접 조회
        - 장점 : 만료된 데이터만 간헐적 요청 - 낮은 트래픽, 조회 서비스 장애, 이벤트 누락, 데이터 유실 등에서 가용성 확보 가능
        - 단점 : Command 서비스에 부하 전파, 네트워크 비용 증가, 장애 전파 위험성 검토 필요
    - 조회수 제외
      - 조회수는 트래픽이 매우 높고
        - 조회수 변경마다 게시글 조회 모델을 갱신하는 것은 비효율적
        - 이미 조회 서비스에서 Redis 기반으로 조회수 캐싱 기능 제공
      - 조회수는 실시간 데이터가 아님
        - 백업 단위 기준으로 이벤트 발행하므로 실시간 데이터가 아님
      - 따라서 조회수는 조회수 서비스로 직접 요청

### 게시글 목록 조회 최적화 전략
  - 게시글 서비스의 MySQL DB는 모든 게시글 목록 조회의 트래픽을 받음
    - 캐싱활용 DB 부하 감소
  - 일반적인 캐싱전략
    1. 캐시에서 key를 기반으로 데이터 조회
    2-1. cache hit : 캐시에서 데이터 조회
    2-2. cache miss : 원본 데이터를 가져와 캐시에 저장하고 조회
  - 목록데이터에서 조회 파라미터
    - boardId, page, pageSize
    - boardId, lastArticleId, pageSize
    - 게시글이 작성/삭제될 때마다 캐시만료가 필요
      - 캐시 만료가 잦고, cache hit 감소
    - 게시글 생성/삭제마다 캐시에 미리 목록을 생성
      - 모든 데이터를 캐시할 필요는 없음
      - 게시판의 사용 패턴 분석
        - 모든 사용자는 게시판 클릭시 첫페이지 조회
        - 뒷페이지일수록 조회 횟수가 적어짐
        - hot data vs. cold data
          - hot data: 자주 조회되는 데이터 (최신)
          - cold data: 자주 조회되지 않는 데이터 (과거)
      - 따라서, 최신 1000개의 데이터만 캐시하고, 1000개 이후로는 게시글 서비스로 요청
      - ArticleRead 서비스는 게시글 생성/삭제 이벤트를 수신
      - Redis에 게시판별 게시글 목록 저장
        - Sorted Set 활용 최신순 1000개 유지
        - key: article-list:board:{boardId}